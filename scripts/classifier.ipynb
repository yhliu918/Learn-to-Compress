{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from scipy.stats import norm, lognorm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=np.loadtxt('../train_data_try/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5773193"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd[:,:-1]\n",
    "y = dd[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=True,\n",
    "                                                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#reg = LinearRegression().fit(X, y)\n",
    "#reg = linear_model.Ridge(alpha=0.1).fit(X,y)\n",
    "#reg = linear_model.Lasso(alpha=0.1).fit(X,y)\n",
    "#reg = linear_model.LassoLars(alpha=.1).fit(X,y)\n",
    "reg = DecisionTreeRegressor(random_state=0,max_depth=5).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.00\n",
      "Coefficient of determination: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_pred = reg.predict(X_test)\n",
    "#for i in range(len(y_pred)):\n",
    "    #print(str(y_pred[i])+\"   \"+str(y_test[i]))\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 190.26, 'X[5] <= 2.5\\nmse = 0.551\\nsamples = 5773193\\nvalue = 0.673'),\n",
       " Text(83.7, 135.9, 'X[5] <= 1.5\\nmse = 0.012\\nsamples = 4329893\\nvalue = 0.263'),\n",
       " Text(41.85, 81.53999999999999, 'X[2] <= 0.237\\nmse = 0.009\\nsamples = 2886593\\nvalue = 0.215'),\n",
       " Text(20.925, 27.180000000000007, 'mse = 0.004\\nsamples = 749569\\nvalue = 0.088'),\n",
       " Text(62.775000000000006, 27.180000000000007, 'mse = 0.003\\nsamples = 2137024\\nvalue = 0.259'),\n",
       " Text(125.55000000000001, 81.53999999999999, 'X[0] <= 14.5\\nmse = 0.005\\nsamples = 1443300\\nvalue = 0.361'),\n",
       " Text(104.625, 27.180000000000007, 'mse = 0.001\\nsamples = 1073722\\nvalue = 0.324'),\n",
       " Text(146.475, 27.180000000000007, 'mse = 0.002\\nsamples = 369578\\nvalue = 0.467'),\n",
       " Text(251.10000000000002, 135.9, 'X[4] <= 1.5\\nmse = 0.157\\nsamples = 1443300\\nvalue = 1.901'),\n",
       " Text(209.25, 81.53999999999999, 'X[2] <= 0.0\\nmse = 0.003\\nsamples = 1356042\\nvalue = 1.999'),\n",
       " Text(188.32500000000002, 27.180000000000007, 'mse = 0.116\\nsamples = 10833\\nvalue = 1.791'),\n",
       " Text(230.175, 27.180000000000007, 'mse = 0.002\\nsamples = 1345209\\nvalue = 2.001'),\n",
       " Text(292.95, 81.53999999999999, 'X[4] <= 3.5\\nmse = 0.039\\nsamples = 87258\\nvalue = 0.367'),\n",
       " Text(272.02500000000003, 27.180000000000007, 'mse = 0.02\\nsamples = 17930\\nvalue = 0.699'),\n",
       " Text(313.875, 27.180000000000007, 'mse = 0.008\\nsamples = 69328\\nvalue = 0.281')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzrUlEQVR4nO3df3RV5Z3o//eHBDhACBESgjGRENAGiJRf4wWLFRBaLXaq1ntR6g+GDlVva8dvexl7q11jr84sv19ZcwXqDJ1RDKD8CBUrLUr5KRZTfiRCAoEkECZKkpJAEgocckJ+PN8/9slp+H2SnLP3Pjmf11qsBayTsz/7c/b+5DnP8+znEWMMSiml7NHD6QCUUiqaaNFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbadFVSikbxTodgOr++vTpc9Ln8yU7HUcwPB5PdUNDwxCn41DdlxhjnI5BdXMiYiLlOhMRjDHidByq+9LuBaWUspF2LyjXWLNmDf369SMjI4P169czfPhw4uPjmTFjBq+//jq/+MUvLnl9a2srPXpc2m4oLi5mz549jBs3jjFjxrBkyRKysrKYNm2anaei1DVpS1e5xn333UdOTg6jR48mLS2NlJQUmpub8Xq9pKWlAdDQ0MCaNWvYsGEDtbW17Nq1i02bNnH48GEAMjMz6dWrF4MGDQIgNTWV+vp6x85Jqctp0VWusW7dOp577jn27t0LQHJyMufPn6eysjLwGo/HQ0ZGBmC1dJubm2lubqalpQWAHTt2UFJSQkxMDEVFRSQlJVFeXk5zc7P9J6TUVehAmgq7zgykrV69mscee+ya/w4XHUhT4aZFV4VdOGcv5OTkUF9fz+zZs0lISODll1/m4YcfZt++fdx888184xvf4JlnnuGtt94KNlYtuiqsdCBNucLChQsBqw+2b9++FBYW8sADD7Bz5068Xi8LFizAGMP27dsBGDt2LEOGDMHn8zF9+nSOHDnC5MmTSU1Npa6ujpSUFLxeLy0tLUyZMsXJU1PqEtqnq1whMTGRiRMnMmnSJOrq6hgzZgy7d+8GICsri9jYWIwxgT7c1tZWwOrj3bZtG+np6ZSVlZGUlMSxY8dITk7m1KlTnDlzhoKCAgoLC508PaUCtHtBhZ0+HKHUX2lLVymlbKR9usqVsrOzmTt3blCvbXsAYtSoUWzdupXW1lbS09PJycnhpZdeIjc3lz59+uDxeCgvL+e2226jqqqKgQMH0rNnT/Ly8vjJT34S3hNSyk+LrrLN4sWLGTt2LCdOnKC0tJRp06Zx9OhRqqqqSExMJC4ujgEDBtCvXz8AFi1ahNfr5bbbbqOxsZHHH3+cixcvXjGY1vYARHJyMjExMXznO9+hX79+lJaWkpycTFNTEwkJCUydOpXs7GyGDx8e6OudPXs2O3fudDItKspo94KyTdvgmM/no66uDoCZM2cydOjQQKH196kGfiYrK4usrCwKCwtpaWm56mBa+wcgzp8/T1xcHH/84x+5++67OXHiBD179uTChQuBAbXevXtz/vx5JkyYQHFxMb169bI/GSpq6UCaCrtgB9I60qUQLjqQpsJNi64Ku87MXuhIAS4pKWHPnj0kJSVx//33s3nzZv7yl7/wzW9+k08++YTS0lKmTp3K1q1bWbBgATExMdeLVYuuCivt01WOW758OXFxcQwePJgtW7Ywf/58wCq8sbGxpKSkkJuby6xZsxg3bhz5+fmcOnWKpKQkJkyYQH5+PnPmzGHVqlUAfP7552RlZXHx4kXi4uJ46KGHuOmmm/B6vU6eplKA9ukqF0hJSaGqqora2lpSU1MpKysD4Ny5c5SUlODz+Rg9ejTx8fEAtLS0XLLIzfjx41m9ejWJiYkUFRWRmZmJ1+ulsrKS48ePM3z4cEpKSoiPj8fn8zl2nkqBdi8oG+jDEUr9lbZ0lVLKRtqnq8LO4/FUi0jEbEzpdAyqe9PuBWULERkMLAYmAH9vjHH8iQQRuR14C6vx8ffGmMMOh6SigHYvqLASy+PAQeBL4KtuKLgAxphSYCrwLvCpiLwkIj2djUp1d9rSVWEjImnAUiANmGeMyXM4pGsSkVuBXwMpWLHmOxyS6qa0patCTkR6iMizwH5gNzDRzQUXwBjzJfAt4HXgIxH5f0Wkj8NhqW5IW7oqpETkNqx+0t7A940xRQ6H1GH+/uclwDisvt5PHQ5JdSPa0lUhISKxIvKPwJ+AD4CvRWLBBTDG1BhjZgP/CKwSkX8TkXin41LdgxZd1WUi8lVgD/AN4E5jzBvGmBaHw+oyY8xvgSygF3BIRL7lbESqO9DuBdVpItIbeAl4GvgZ8E7EPHrWQSJyL/CfQC7wvDHmtMMhqQilLV3VKSIyGWug7A5grDFmWXctuADGmG1Y53oKOCgis0VEHxdWHaYtXdUhIhIHvArMBn4M/KY7F9urEZFJwNvAMeB/GmMqHQ5JRRBt6aqgichMrIccBgFZxph10VZwAYwxu4HxQAFwQET+Xlu9Klja0lU3JCI3AQuBGcAzxpiPHQ7JNURkDFar9yzwA2NMmcMhKZfTlq66LhF5CDgENGC1brXgtmOMKQQmAx8De0TkJyJy7a0pVNTTlq66KhEZgvWAwFexHnL4o8MhuZ6IjMB6MKQPVs4OORySciFt6apL+BeoeRKrv/IY1gI1WnCDYIw5BkwHlgE7ROSfRES3GlaX0JauChCRoViLviRjtdQ+dzikiCUiqViL/QzFWkBnn8MhKZfQlq5qW6Dmh0A+8CnWU2VacLvAGFMBfBv4F+B3IrJQRPo6HJZyAW3pRjkR+QpWP2QPrNZtscMhdTsikgQsAu7EWkDnE2cjUk7Slm6UEpGeIvIz4DMgB7hbC254GGNOGWPmAP8PsFJEfi0iA5yOSzlDi24UEpFxWAvUTMNa63aJMabV4bC6PWPM77AW0DFYC+g84HBIygHavRBFRMQD/AKYDywAVkTjE2VuICLTsBbQ2Qv8gzHmlMMhKZtoSzdKiMjXgAPAV4AxxpjlWnCdY4zZAYwBKrEW0JmjjxJHB23pdnMi0h9rBP27wHPGmPcdDkldRkTuxHqUuBx41j/zQXVT2tLtxkTkm1gL1PTDeoRXC64LGWP2Ym1Nvw/YLyJPi4jem92UtnS7IREZCPwrcA/wtDFms8MhqSCJyGisVm8DMN//lJvqRvS3aTcjIt/FWqDmL8AdWnAji39fua8BG4DdIvK/RCTW4bBUCGlLt5sQkZuBXwGjsCbgf+ZwSKqLRCQDa4ZDf6wHVw46HJIKAW3pRjj/AjVzsRaoOQKM04LbPRhjjmOtYfxrYJuI/NK/L52KYNrSjVAicgfwEDAFayeH7xtjDjgalAobEUkB/g0YgdXnW2aM2eBsVKoztOhGIP98zmNAGlaXwj8aY5qdjUqFm/9z/3vgDf9/petDFZFHuxci0wCgF7AR+K0W3Ojgf5hlK7Aea1fiic5GpDpDW7pKKWUjnYpyDX369Dnp8/mSnY7jRjweT3VDQ8MQp+NQ9omUaxP0+rwabeleg4hExNIEIoIxRp/ZjyKRcm2CXp9Xo326SillIy26XbBmzRp+97vfUVRUxCuvvMKqVav4/e9/j8/n45VXXrni9a2tVy5ZW1FRwUsvvRT495IlS9ixY0dY41bR4fLrE+DFF1+kvLw86OvzzJkzPP/884F/v/3223z00UdhizkaaNHtgvvuu4+cnBxGjx5NWloaKSkpNDc34/V6SUtLA6ChoYE1a9awYcMGamtr2bVrF5s2beLw4cMApKamMmLEiMB7pqamUl9f78j5qO7l8uuzrKyMxMREgMD1CbB27Vo2bNjAiRMnyM/PZ9OmTeTn5wOQkJDA2LFjA69NSUnhwoULNDY22nou3YkW3S5Yt24dzz33HHv37gUgOTmZ8+fPU1lZGXiNx+MhIyMDsFoSzc3NNDc309LSAkBtbS0FBQVUVlZSVFREUlIS5eXlNDfrLDDVNZdfn8ePH6epqYmKiktXjhw5ciRgXZ8tLS2XXJ8NDQ0UFBRw7NgxioqKSE5O5tSpU5w5c8bWc+lOdCDtGjo6WLF69Woee+yxa/47XHSgIvp0ZiBNr0/30KJ7DeEaIc7JyaG+vp7Zs2eTkJDA0qVL6dGjB9/61rdYunQpr776Kh9++CEnT57k6aefDiZOvaijTDhnL1x+fWZnZ5Oenk5VVRXx8fFMnTqVTz75hLy8PF5++eVgYtXr8zI6T7eTFi5cCFh9sH379qWwsJAHHniAnTt34vV6WbBgAcYYtm/fDsDYsWMZMmQIPp+P6dOnc+TIESZPnkzfvn0D79PWtztt2jTWrl3rzImpbiFU1+fUqVMpLy8nJSWFM2fO0NjYyMiRI+nXr5+TpxfRtE+3kxITE5k4cSKTJk2irq6OMWPGsHv3bgCysrKIjY3FGBPow20bGfZ4PGzbto309HTKysrwer00NDRc0re7YMGCSwbXlOqoUF2fBQUFFBYWXjJesXPnTu655x4nTy+iaffCNUTKBHT9+hZ9IuXaBL0+r0ZbukopZSPt0w2R7Oxs5s6dG9RrW1pamDdvHm+++Sbbtm2jqamJIUOGkJuby4MPPsgf//hHkpKSOHv2LLW1tUydOpW8vDySkpJISUlh69atLFiwgJiYmPCelOo2OnJ95uXlsXv3bn70ox+xZcsWKisreeKJJ664ZtPT09m6dSvz589n3bp1JCYm0traeslAnLqSFt3rWLx4MWPHjuXEiROUlpYybdo0jh49SlVVFYmJicTFxTFgwIDAoMKiRYvwer3cdtttNDY28vjjj3Px4sUrBis2b97MnXfeSVxcHP3796e2tpYpU6awd+9eUlNTSUxM5ODBg9x8883U1dUxbNgwysvLOXjwIFOmTMHr9TqZFuUS4bo+J06cyKFDhwIP+gBXvWYzMjLwer0UFxczY8YMcnNzAS4ZiFNX0u6F62gbfPD5fNTV1QEwc+ZMhg4dGriQ/X1WgZ/JysoiKyuLwsJCWlparjpYcfbsWY4fP051dTXnzp2jtbWVhQsXMnDgQGJiYmhubuaOO+7AGMPgwYM5c+ZM4P9KSkqIj4/H5/PZnxDlKuG6PktLSwMPRLS0tFBRUXHVa7btWmxr8fbt2zcwEJeZmWl/QiKEDqRdQzCDFR35yhYuOlARfYIdSNPr05206F5DpIwQ60UdfSLl2gS9Pq9GuxdCJDs7O+jXlpSUsGLFCj7++GMAPv/8c5YsWUJNTQ1vvPEG+/btIy8vj9deey3wDLxSndWRa/PyVcVycnJYtmwZlZWVLFmyhJUrV1JcXMxrr70W+kCjhA6kdcLy5cuJi4tj8ODBbNmyhfnz5wPWxR0bG0tKSgq5ubnMmjWLcePGkZ+fz6lTp0hKSmLChAnk5+czZ84cVq1aBcD48ePZs2cPzc3N1NXV4fP5GD16tA6YqQ7r6rV5+apimZmZHDhwgJ07dzJy5EiqqqrIzMxkyBDdDKKztOh2QkpKCsXFxcTExJCamkpZWRkA586do6amhoEDBzJ69Gji4+MBrli5afz48axevZrExESKioo4cOAAjY2N9OvXj4SEBMrKyoiNjQ0MmOkjlypYXb02268q1tjYSJ8+fTh79iyzZ89m9erVJCQkUFFRQUFBAfX19dx0002OnWuk0j7da4iUfjPtM4s+kXJtgl6fV6Mt3WvweDzVIuL6zf88Hk+10zEoe0XKtQl6fV6NtnS7SEQEWAvUG2NuvBbjtd+nF/ApsN4Y8/+FKj4V3UTkm8AyYKIx5s9deJ+ngR8Bk4wxOtjQBVp0u0hE/gF4EviaMaZLTyyIyK3AXmC2MWZnKOJT0SuU15O/cbHc/8+nIqZ/w4W06HaBiNwFfID12/+/QvSe3wDeoYstExXdwvHNSUT6AnuAXxljfh2K94xGWnQ7SUQGA/nAM8aYjSF+738CpgP3GmN0szTVYSKyBEgDHgplq1REbgc+A+43xuSF6n2jiT4c0QkiEgOsAlaEuuD6vQI0AP8ShvdW3ZyIPAbcD8wNdTeAMaYUeBZYJyIDQ/ne0UJbup0gIq8Ck4FvGGPC8siYiCRitaSfN8Z8EI5jqO5HREYBO4GZxpgDYTzOvwKZwAPGmNZwHac70pZuB4nILOAp4LFwFVwAY8xp4L8DvxaR28J1HNV9iEh/4H3ghXAWXL8XgHjg52E+TrejLd0OEJF0rIGEh40xn9l0zB8CPwAmG2Mu2HFMFXn8swtWA15jzPdtOuYtQB7whDFmqx3H7A606AZJRDzALuA9Y8z/tfG4ArwHNALzdKqOuhoReQ6YB9xljGmw8bjTsa7PvzHGVNh13EimRTdIIrIUGAT8D7sLn4jEYc23/FdjzFt2Hlu5n4hMAjZgfRsqc+D4PwceAKYaYy7affxIo0U3CCLyBPAS1m/zsw7FkAn8EfimMeZzJ2JQ7iMiSVgDrs8ZYz50KIYewIdAmTHmeSdiiCRadG9ARO4AtgPTjTEHHY5lNtY0sonGmHonY1HO809d/BjYb4x5weFYbsIq/j8zxuQ4GYvbadG9DhGJB/YBrxpjVjodD4CILAKGAQ/qVJ3oJiK/BO4BZrjhIRoRmQBsAu42xhQ7HY9badG9Bv8A1jrglDHmWafjaeN/vPMTYIMxRpfvj1Iicj/wn1jfek46HU8bEZkP/APw33RhnKvTonsNIvIT4DFgijGm0el42hORVKwW+BxjzA6n41H2EpGhWAOrjxhj/uh0PO35GyvvYC0b+4TOtrmSFt2rEJEpWJPM/5sxptzhcK5KRGZirfr0N8aYSqfjUfYQkd5YUxfXGmMWOh3P1fgXxvkTsNQY8+9Ox+M2WnQv418cOh/4gTHmI6fjuR4R+QXwTWCaMabJ6XhU+InIvwFDgO+6uRXpf4ryM2CWMWaf0/G4iT4G3I6IxGI91fOO2wuu3z8DZwHt240CIvI9YCbwd24uuADGmKPAM1gL4wxyOh430ZZuOyLyL8DfAPeFc12FUPJf0PnAT40x7zsdjwoPERmNNYA6wxhT4HA4QRORhcBorBavzrZBW7oBIvJt4HGswamIKLgAxpharIVxlvrXOlXdTLuFbP5XJBVcv/8NxGE9XKTQli4AIpKB1fH/oDHmT07H0xki8gzwP7F2sdCFcbqJdnvwnTHG/MDpeDpDRFKwFsaZa4zZ7HQ8Tov6outfyOYzrAXJFzkdT2f5b84VQCthWLxaOSOUe/A5SUSmAmuwZtuccDYaZ2nRFfkPYADwaKQXKhHph7X05GJjzH84HY/qmnDsweckEfkZ8CDw9WheGCeqi66IzAV+hvXb95zD4YSEiHwFax6n7mEVwdrtwfesMeb3TscTCv6FcX4LlBtjfuxwOI6J2qIrIl8FtmItR1fkdDyhJCKPAK8DE4wxdU7HozrGv5DNH4C9xphutTODf2GcPOBFY8wap+NxQlQWXREZgPXB/5MxZpXT8YSDiPxf4Hbg2zpVJ7L49+C7C2sPPscXsgk1ERkHbMbqZjjidDx2i7qi6x9wWg9UGWN+6HQ84SIiPYEdwMfGmH92Oh4VHP8efEuxFrKpdjqecBGR7wM/Be40xpx3Oh47RVXR9a+Nez/wXazfsq5ayCbU/HtY7cOaSnbAretIKBCRBCALaz6ubXvwOUlElgEe4HVjzH6n47FLtBXdKqAv1lM9UTHIJCJ/BywGdhpjHnA6HnV1IvIS8DywKloGmfy/aPKBFOCWaBl/iJon0kRkIHAzcA6Ipukq9YAA05wORF3XY8BNQDRt7ihALVZr9z6HY7FN1LR0/dNVngDejaTHfEPBP3/3b40xq52ORV2diNwHlHSH+bgdJSLfxfomdtrpWOwQNUVXKaXcIGq6F5RSyg1i7T5gnz59Tvp8vmS7j9tRHo+nuqGhYYjTcVxPpOQSNJ+hFgn5bOPWvDqVQ9u7F0QkIpY4EBGMMeJ0HNcTKbkEzWeoRUI+27g1r07lULsXlFLKRq4qumvWrOF3v/sdRUVFvPLKKxQXF7N8+XIKCwt55ZVXrnh9a+uVT7eWlJSwYsUKPv74YwA+//xzlixZQnV1Nb/97W9ZsWIFhw8f5uc//zlffPFF2M/JaZfndNeuXaxdu5bc3Nygc3rmzBmef/55AM6dO8ezz/51R/oXXniBY8eOhS1+NwrHdbpx40ZWrlzJ0aNHwx6/m1yeS4AXX3yR8vLyoHNZXV3NBx98wKZNmwB4++23+egj9+625aqie99995GTk8Po0aNJS0sjMzOTXr16MWjQINLS0gKvW7t2LRs2bODEiRPk5+ezadMm8vPzAcjPz2fOnDmcOnUKgPHjxxMbG0v//v1JS0ujsbGRUaNGMWzYMIYOHerIedrp8pweP36c2bNnc+zYsaBzmpCQwNixYwHYvHkzd955Z+DnUlNTqa2ttfWcnBaO67S2tpZHH32UvLyoeGYn4PJclpWVkZiYCBB0LpOTk2lqaqJ3794ApKSkcOHCBRob3fnAqauK7rp163juuefYu3cvADt27KCkpISYmJhLXjdy5EjA+q3X0tJCc3MzLS3W1Nvx48ezevVqEhMTKSoq4r333qOxsZGmpiYqKyuJiYnhwoULxMXF2XtyDrk8p+np6eTk5JCRkXHJ666X04aGBgoKCjh27Bjnzp3j0KFDfPnll3zxxRcMHTo06lq64bhOBw4cyJo1axg/fry9J+Owy3N5/PhxmpqaqKi49BmR6+XyxIkT9OzZkwsXLlBUVERycjKnTp3izJkztp5L0Iwxtv6xDnljq1atuu6/w80fp+356cifYHPZxsmcdsd8GuNcTiMhn21/3HrPO5XDbjN7IScnh/r6embPnk1CQgJLly6lR48ejBo1isrKStLS0ti9ezcJCQnMmzcvmDgxLh8dDueocDD53Lx5Mw8//DBjxowJJlbN5w3yefbsWcrLy3nmmWeCidX1+WwTjrxeK58zZ87k008/5atf/Srbt2+/7v3uVA5tn6d7IwsXLgSsvsK+fftSWFjIAw88wM6dO/F6vSxYsABjDNu3bwdg7NixDBkyBJ/Px/Tp0zly5AiTJ0+mb9++gPV15cknn2TFihWMHj2azZuja1+8cOYzNTWVurqoWKMkIJz5nDx5MocPH3bs3JwQ6nwOGzaMDz/8kD59+rj2fndVny5AYmIiEydOZNKkSdTV1TFmzBh2794NQFZWFrGxsRhjaG5uprm5OTCa6fF42LZtG+np6ZSVleH1emloaLikDzM2NpbMzEwnT8924cxnUlJS1PXnhjOfxcXF9OzZ08nTs12o81laWkpSUhL19fWuvd+7TfdCqEXC17dIySVoPkMtEvLZxq151e6Fa8jOzmbu3LlBvXbXrl3k5uby1FNPkZOTw+DBg2lqaqK2tpZ58+axbNkyZsyYwcaNG7nnnnuoqanB5/MxYsQIqqurg+5Pi2QdyWdeXh67d+/mRz/6EVu2bKGyspInnniCefPm8eabb7Jt2zaamppIT09n69atzJ8/n3Xr1pGYmEhra+slfW7dVWfyOXfu3EDu/vznP5OVlUVGRgZ/+MMfmDFjBps3b6ZHjx784Ac/4MUXX2T+/PkUFBRw8uRJnn766fCekEt0JK/vvvsutbW1zJ07l507d1JaWsqkSZPIzc3l4Ycf5sMPP+TRRx9l48aNnDt3jp/+9KfhDf4GHCm6ixcvZuzYsZw4cYLS0lKmTZvG0aNHqaqqIjExkbi4OAYMGEC/fv0AWLRoEV6vl9tuu43GxkYef/xxLl68eEU/z5QpU9i7dy+9e/fm9OnTJCYmcvHiRerq6ti/fz89e/akoaGBW265hbq6OjIzMzl69Cj5+fncc889EdufFq58Tpw4kUOHDtHc3IzX6wX+Ok83Li6O/v37U1tbS0ZGBl6vl+LiYmbMmEFubi7AJX1ukSTc+Wyfu9TUVOrr6/nTn/7EoEGDuHDhQqB/sv2c1WnTprF27VpnEhIi4cpr2z3ep08f4uLieOihhxg+fDh79+6lf//+JCYmUltbS0NDAz6fz8kUAA716bb12/h8vsBAzMyZMxk6dGgg4f6mf+BnsrKyyMrKorCwkJaWlqv28yxcuJCBAwdSXV1NWloaTU1NGGMYPHgwI0aMoLW1lbKyMgYPHszRo0fp06cPJ0+e5K677oro/rRw5bO0tDQwP7elpYWKigrOnj3L8ePHqa6u5ty5c7S2tlJSUkJ8fHygxdu3b99An5sb+9RuJNz5rKioCOQuKSmJ8vJysrKyOH/+PMePHw/0T7afs7pgwQJGjBhhfzJCKFx5bbvH6+rqOH78OMOHDw/Ugh49ejBo0CDKysqIiYmhV69eNDc7vNen3XPUCGLO3jvvvHPD14QbETAPMphcGqP5DPaP5jO68upUDnUg7RoiYaAiUnIJms9Qi4R8tnFrXnWVsWvIzs4O+rXXWuympqaGl19+mfLyctcvhhFuXclnUVERixcvprq6mjfeeIN9+/aRl5fHr371qzBF634dyWf7hYPAmuC/bNkyvvzySxYtWsSaNWsC/1dVVRX6YF0uHNfmj3/8Yy5cuBCmiDvHVbMXli9fTlxcHIMHD2bLli3Mnz8fsD6M2NhYUlJSyM3NZdasWYwbN478/HxOnTpFUlISEyZMCCwismrVKsB6vn3Pnj3ExcUxdepUwFoMw+v10tjYGFggo7sKdT4zMjJYv349ra2t1NXV4fP5uPvuuzl06JCTp2mbruaz/cJBAJmZmRw4cIDDhw+Tnp7O3r17mT17NgcOHKCwsJCUlBSHzjT87Lo29+/fHxiYdAtXFd2UlBSKi4uJiYkhNTWVsrIywFpOsKamhoEDBzJ69Gji4+MBbriIyIEDBwKL3RQUFHD27FlSU1PZs2cPZ86cITnZdYvZh1So89nU1MSgQYO4ePEiCQkJlJWVkZycTEFBAT6fD4/H49i52qGr+Wy/cFBjYyN9+vTh7Nmz3H///ezevZtRo0Zd8n/dmR3X5q233sqwYcMcO8dr0T7da4iEPrNIySVoPkMtEvLZxq151T5dpZSKArZ3L3g8nmoRcf33eo/HU+10DDcSKbkEzWeoRUI+27g1r07l0Pbuha4QkQnAOmCEMebKfTv++ro/Af9sjPm9bcFFIBF5GRhkjHnuOq8ZAhwB0owx5+2KLRKJSD7wv40x11zaSkTmAg8bY/7WtsAikIikAQeAVGNMw3Ve9z7wB2PMf9gVW1dFWvfCPGDZ9Qqu39v+16prEJEewN9h5eqajDEngU+B/25HXJFKRMYCicC2G7x0HTBFRG4Oe1CR7Slg7fUKrl/E3esRU3RFpA/wKLA8iJfnANPc+JXGRe4Fao0xB4J47TLg++ENJ+LNA7KNMS3Xe5Exxgu8DzxpS1QRyN8gmId13d3IZiBNREaHN6rQiZiiCzwM7DXGnLjRC40xZ4HfAk+EO6gI9n1u0Mpt5yNghIhE3kIKNhARDzAHeCfIH3kbmCciETH7wAFTgXNA/o1eaIxpBrKJoEZBJBXdYH/ztVmGXthXJSIDgfuAVcG83hjTBKzA6o5QV/oOcMAYUx7k6/cALcDXwhZRZGvrRgx2wOkd4HER6RXGmEImIoquiGQAY4ANHfixXVizMyaFJajI9j3gI2NMfQd+ZhnwpIhE5lJs4dWRbw34i8nbRFDrzC4ikgA8ALwb7M8YY44Bh4FvhymskIqIogvMBd4zxgS9kb3/wl5GhHWy26Sj3xowxhQDx4Hu/ahUB4nIUGACVndWR6wEHhSR/iEPKrI9Bmw2xtR28Oci5l53fdEVkRisoht0S6Kd5cAjIhIX0qAimIiMB24Ctnfix7V1dqW5wOogRtkvYYypAXYAs8MRVATr0LeGdn4DTBaRW0IcT8i5vugCM4BqY8zBjv6gMebPWN0Mj4Q8qsg1D3gniGl3V7MO+Lp/7m7UazftrkPfGtqJmNaZHUTkq8BgYGtHf9YYcwHr+nwq1HGFWiQU3c7+5mujrTM//7S7x7BGezvMGHMOWI9Od2ozHag3xnzeyZ/fBKSLyMgQxhTJgpp2dx1ts0JcXddcHZyIDAK+AazpwttsBG4Tka+EJqqI9iCQb4z5ogvvsQz4vs4KATrRN96ef7rTcrRRgIj0xpp2l92Ft9kH+ICvhyKmcHF10QUeB35njDnT2TfwT3daiU53gq5/awDIBVqBu7oeTuQSkZuAbwHvdfGtlmFNd4r2WSHfAQqNMcc7+wbtZoW4usvGtUXX35IKRZEA68J+SkRctX6wnURkGDCWjo+yX6LdrJBob519D/jYGFPXlTcxxhwFSrCmSUWzeYTmXn8X+FsRGRCC9woL1xZdrGk4/bCe++8SY8wR4L+I7ulOc4FVHZl2dx0rgYeifLpTl7oWLhPVA2oicivwN8AHXX0vY8wprIG4R7v6XuHi5qL7fYJb3CZYUTug5p92d8PFbYLlXwRnJ/A/QvF+kUZExgGDuPHiNsH6DfA1Eem++/Nc31PAmo5Ou7sOV3cxuLLoikhfrBs6mMVtgpUDTI3S6U73AqeMMQUhfM9obp11ZdrdFfyL4PyGKJwV0sHFbYK1GbhFRLJC+J4h48qii7W4zR5jTEWo3rDddKdoXAQnVH3j7X0EZETbdCf/4jaPEfziNsGK1kVwpgF/ATo77e4K/iln2bj0m61bi26of/O1ibpFcPzT7r4JrA7l+/qnO0XjIjgPAvu7OO3uavYCTcCUEL+v23V0cZtgvQN8z42L4Liu6IrIcCCLji1uE6zPAAEmh+G93ep7wMYOLm4TrGhcBCcc3xqichEc/7S7WXR92t0VjDFlQBHguh06XFd0+eviNhdD/cbRtghOiKfdXcEYUwIcxZqv2u2JSDowji5Ou7uOd4HviEh8mN7fbR7D2mqno4vbBMuV97qrim4XF7cJ1grgu1GyCM54oD/wSRiPEU1zdudiLW7jC8eb+xfB2U70LIITtgaB3/vAJBFJDeMxOsxVRRfrkd8/G2MOhesA7fb8iobpTt8nhKPs17AOuLu77/kV6ml31xEVv8T8e8olEbppd1fwL4KTg8sWwXFb0Q3VUyk34sqvHaHkX9xmNqGddncF/w7B0bDn13SC31OuK/5AhO351Ult0+46u7hNsFy3CI5rAhGRJGAmXVvcJljRsOfXw8A+Y8yXNhwrGqY7hfurMHDJIjjdtlHQbk+5bBsOlwdcwEWL4Lim6GKNsm8wxvwl3AeKkj2/wjXt7mp2Yy2C0y33/OronnIh0LYIjuumO4VI255y/xXuA7lxVogrim67UXa7igR04+lO7faU+9CO47nxwg6xzuwp12n+Pb+K6b6L4NjZIABrVsi33bIIjiuKLjAR6IP1PL8tuvmeX3MJ3eI2werOi+DYXSTA5esHdJZ/T7mJhGBxm2AZY04DW7CmqDnOLUW3bZQ91E+l3Ei3a53ZNO3uCsaYarrhnl/+PeUS6Nyecl3xPnBXJOz51UGhXtwmWK4ZPHe86PoH0EK9uE2wcrD2/BreHQaB/OsFz8LaU67QgRDextpVolvMgRaRftgz7e4K/kVw1gF/5x94inj+b0F2TLu7ms1Aiojc6fRMBkcP7r85i4ETgBMLjPcGjmDN2x3uwPFD7bvAEuBLh36JnAMygf0OHDsc3sL61nDKoeOfAn4C/B+Hjh9qX2I9ht/swLF7Yd3ra3F4wNfplu4FrO3AbwLOO3D8BiAOSAHOOnD8cLgVOO9AVw3AGcCDtfh8d5CINdbgVNGt4q/3R3fQC4jH+uVst4tADJCOVXcc4+j2NcaYVhFZAbzg7+y2+/gXRGQSVovG9uOHwW7gP4GnnTi4MaZARGbSfQYn3wXWGWN+48TBjTH/5h9xP+DE8cNgGfCmHVPFLmeMaRGRb2LNDS62+/jtiTMNIqWUik5Ody8opVR0McZc94/H4zkJGLf+8Xg8J90eY7tYW5yOobvk1OPxnHTzNdoWnxtji8TPvf3n7ea8Xh7n1f7csHtBRBwakwlO2yC9m2NsIyIREye4O6f+XIr/7667Rtvic2Ns1+Lmz7395+3/tyvzenmcV6PdC0opZSNHZi/k5ORQX1/P7NmzSUhIYOnSpfTo0YNRo0ZRWVlJWloaKSkpvPXWW7z66qtOhBh0nGfPnqW8vJxnnnnG1XGWlpaSnp7O1KlTXR3nqVOnOHnyJE8/7cgEjKvGmZ2dTXp6OiNGjGDp0qW8+uqrLF26lJEjR3LPPfe4Jk635vN6sX79619nz549jBs3jjFjxrguvva53LdvH7169eLZZ5/t0rG6VHQXLlwIQGpqKn379qWwsJAHHniAnTt34vV6WbBgAcYYtm+3nqAcO3YsQ4YMwefzMX36dI4cOcLkyZPp27cvAMePH+fJJ59kxYoVVFZWMmLEiC6dnB1xTp48mcOHD7s+zqlTp1JeXu76OB988EHWrl3rqjjbcpeamhq4JouKihg+PDTP00RKPsMRa2ZmJvv372fQoEGujK99Li9cuEBra9cfTOxS90JiYiITJ05k0qRJ1NXVMWbMGHbv3g1AVlYWsbGxGGNobm6mubk5ELDH42Hbtm2kp6dTVlaG1+uloaGB9PR0cnJySE9Pp76+noMHD4akfylccWZkZFBcXEzPnqFZqCyccRYUFFBYGJong8MZ54IFC0L2yzZUcbblrra2loKCAiorK7n99tspKytzVZzhzmc4Yt2xYwclJSXExMS4Mr72uYyNjSUUD3rqQJqNdCAtdHQgLfTc/Ll3p4G0sPTpZmdnM3fu3KBem5eXx4oVK3jttdf47LPPqKysBMDr9XLvvfeyceNGHn30UbZu3crgwYNpbm7G5/MxYsQIxo0bF/b4du3aRW5uLj/5yU945plneOutt8jLy2Pr1q08++yz7Ny5k9LSUm699Vbq6+t55JFH2LVrF83NzTz44IPMmzeP5cs7t5ZPR/O4e/du5syZQ05ODomJiaSnp7NixQpeffVVduzYQVNTU+D/XnjhBfLy8mhubiY5OTlwjrGxnbskOhprW/6ys7OZMWMGn376Ka2trYwePZqKigpmzZrF3r172b59O/feey9/+ctfGDJkCHfffXen4utKrJfn1efzUVtby7x589i+fXsgr1u3bmXBggVdbrV1Jr65c+eybds2mpqaeOihh5g3bx6//OUvef/993n00Uc5fPgwRUVF3H///ezZs4ekpCTKy8tpbW3lhz/8oe3xPvnkk3zyySeUlpaSmJiI1+vlqaeeCpxDa2vrJX2sodCROH/zG+shxJtvvpmqqioGDhxIz549ycvL45FHHiEvL4+4uDjKy8s5d+4cP/3pT4OOI+g7bPHixYwdO5YTJ05QWlrKtGnTOHr0KFVVVSQmJhIXF8eAAQPo18967H7RokV4vV5uu+02Ghsbefzxx7l48eIVfSkTJ05k//799OrVC6/XC8DIkSP59NNPqa6uJjExkdraWoqKihg4cCCZmZkcPXqU/Pz8S4puuOKbMmUKe/fuJTY2lilTpgCQkZGB1+slLi6OuLg4HnroIT777DOmT58eGLCqqalh8+bN3Hnnnbbl8dChQxQXFzNjxgxyc3MDuY2Pj6d///7U1tYG/u+WW27h9OnT1NTUXHKOdsTalr9Dhw7Rs2dPGhoaGDVqFBs2bODuu+/m9OnT1NfXc9ddd1FfX0/v3r05evTodb8m25nX5uZm6urq6N27dyCvbefkVHxxcXGBWNquuz59+gTun6lTp3LkyBHy8/OZM2cOq1atCuTc5/Ph8XhsjTc+Pj5w75w+fZpPP/2UioqKwDlc3sdqd14PHjzIhAkTGD58OGfOnKGgoIDZs2ezc+dObr31Vo4ePcqgQYM4cuQIPl/HNocOuk+3rW/E5/NRV1cHwMyZMxk6dGjghC7/+pyVlUVWVhaFhYW0tLRctS/liy++YNiwYRw7doyWlhYqKirweDzExMSQmZnJoEGDKCsr4/bbb6e8vJw+ffpw8uRJ7rrrLlviW7hwIQMHDqSpqSnQt1dSUkJ8fDw+n4/jx48zfPjwQJ9QRkYG//7v/05KSgpnz57l+PHj1NbWhj3O0tJSCgoKAi2uvn37BnJ7+vRpzp07R2tra+D/qqurA3G2P0c7ctqWv/T0dFpbWykrK6NXr17ceuutDBgwgJ49e1JWVsamTZv41re+RX19PXfccQcnT560/fq8Wl6NMQwePJiamppAXttfE07EV1FREYil7boDAvfPSy+9RFpaGuPHj2f16tUkJiYGcn55wbUj3svvnZiYGAYOHBg4h7b7KTPz+tsYhivOr3zlK9TU1CAinD9/ngkTJlBcXEyvXr04fPgwGzduJD4+npiYGHr16kVzcwcWTrvR0xPWS27snXfeCep1oYb/SZAbcSq+9iIpTrfH6o8v6GvU7ljb4nP7/dNesJ+7Mc7l07i8Ll0e59X+6ECajXQgLXR0IC303Py5d6eBtJA+kZadnR30a0tKSlixYgUff/wxABs3bmTlypWUlJTw+uuvk52dzfr161m2bFnIpuaEIs7PP/+cJUuWUFNTwwsvvMCxY8fIzs7mzTff7HDfTjjjLCoqYvHixVRXV/PBBx+wcuVKAL73ve+FNMauxtkWU2trK2+88Qb79u0jLy+PH//4x1y4ENplTzsS55kzZ3j++ecD/z58+DA///nP+eKLL1i0aBFr1qyhuLiY1157LaQxdjTOL7/8kvXr17N582bg0vtoyZIlrFy5MixxduUz37x5M+vWraOwsJC3336bDRs2uPIean+vt9WkUOSy07MXli9fTlxcHIMHD2bLli3Mnz8fsE4yNjaWlJQUcnNzmTVrFuPGjSM/P59Tp06RlJTEhAkTLunQB6itreWxxx4jJyeH8+fPM2DAAIwxVFRUBCYquyHO8ePHs2fPHuLi4khNTaW2tjYw8FdeXn7DPii74szIyGD9+vX06tWLiRMnkpuby+7duxk5cmSncxmOONtiqqmpoa6uDp/Px913383+/fsd/dwTEhIYO3Zs4P1GjRrFsGHDGDp0KOnp6ezdu5dHH32UIUOGdD6ZIYiz/aAOXHofjRw5kqqqKjIzM7sUZ6g/888//5ysrCwSEhJITEzk4MGDgRksbrqH2t/rbTWpq7mELrR0U1JSqKqqora2ltTU1EBr9Ny5c5SUlODz+Rg9ejTx8fEAtLS00NzcTEtLS+CE2jr022YmrFmzJvBhGGNobGxk+PDh1x1AsTvO9957j8bGRpqamhg6dCjHjh0LDARkZGS4Js6SkhIGDRrE2bNnefnll8nIyKCmpob6+noqKipcE2dbTM3NzSQkJFBWVhYY7OuKrsbZ0NBAQUEBx44do6ioiAsXLhAXZ2391vZ4aEVFBQUFBdTX1zsWZ/tBnfb30cSJEwNPSnY1zlB/5pmZmXi93sDnfscdd7jyHmp/r7fVpFB85tqnayPt0w0d7dMNPTd/7tqnq5RSqlNu2Kfr8XiqRSTZjmA6w+PxVAO4OcY2Ho+n1entn4MRCTlti7Ht726LtS0+N8Z2LW7+3Nt/3m3/joQ4r0b3SFNKKRu5vtWllFLdiRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSykRZdpZSy0f8Pzj1lEBUelDwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(reg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:35:07] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:35:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:1.10356\ttest-mlogloss:1.10379\n",
      "[1]\ttrain-mlogloss:0.91713\ttest-mlogloss:0.91763\n",
      "[2]\ttrain-mlogloss:0.78289\ttest-mlogloss:0.78384\n",
      "[3]\ttrain-mlogloss:0.68220\ttest-mlogloss:0.68294\n",
      "[4]\ttrain-mlogloss:0.60428\ttest-mlogloss:0.60526\n",
      "[5]\ttrain-mlogloss:0.54320\ttest-mlogloss:0.54434\n",
      "[6]\ttrain-mlogloss:0.49493\ttest-mlogloss:0.49591\n",
      "[7]\ttrain-mlogloss:0.45599\ttest-mlogloss:0.45720\n",
      "[8]\ttrain-mlogloss:0.42464\ttest-mlogloss:0.42589\n",
      "[9]\ttrain-mlogloss:0.39896\ttest-mlogloss:0.40036\n",
      "[10]\ttrain-mlogloss:0.37805\ttest-mlogloss:0.37945\n",
      "[11]\ttrain-mlogloss:0.36069\ttest-mlogloss:0.36227\n",
      "[12]\ttrain-mlogloss:0.34648\ttest-mlogloss:0.34799\n",
      "[13]\ttrain-mlogloss:0.33455\ttest-mlogloss:0.33616\n",
      "[14]\ttrain-mlogloss:0.32460\ttest-mlogloss:0.32624\n",
      "[15]\ttrain-mlogloss:0.31627\ttest-mlogloss:0.31792\n",
      "[16]\ttrain-mlogloss:0.30927\ttest-mlogloss:0.31095\n",
      "[17]\ttrain-mlogloss:0.30330\ttest-mlogloss:0.30501\n",
      "[18]\ttrain-mlogloss:0.29828\ttest-mlogloss:0.29996\n",
      "[19]\ttrain-mlogloss:0.29397\ttest-mlogloss:0.29570\n",
      "[20]\ttrain-mlogloss:0.29031\ttest-mlogloss:0.29204\n",
      "[21]\ttrain-mlogloss:0.28716\ttest-mlogloss:0.28895\n",
      "[22]\ttrain-mlogloss:0.28448\ttest-mlogloss:0.28625\n",
      "[23]\ttrain-mlogloss:0.28210\ttest-mlogloss:0.28396\n",
      "[24]\ttrain-mlogloss:0.28013\ttest-mlogloss:0.28196\n",
      "[25]\ttrain-mlogloss:0.27829\ttest-mlogloss:0.28022\n",
      "[26]\ttrain-mlogloss:0.27679\ttest-mlogloss:0.27875\n",
      "[27]\ttrain-mlogloss:0.27550\ttest-mlogloss:0.27741\n",
      "[28]\ttrain-mlogloss:0.27431\ttest-mlogloss:0.27629\n",
      "[29]\ttrain-mlogloss:0.27323\ttest-mlogloss:0.27528\n",
      "[30]\ttrain-mlogloss:0.27235\ttest-mlogloss:0.27441\n",
      "[31]\ttrain-mlogloss:0.27154\ttest-mlogloss:0.27361\n",
      "[32]\ttrain-mlogloss:0.27081\ttest-mlogloss:0.27294\n",
      "[33]\ttrain-mlogloss:0.27011\ttest-mlogloss:0.27234\n",
      "[34]\ttrain-mlogloss:0.26960\ttest-mlogloss:0.27184\n",
      "[35]\ttrain-mlogloss:0.26904\ttest-mlogloss:0.27138\n",
      "[36]\ttrain-mlogloss:0.26862\ttest-mlogloss:0.27096\n",
      "[37]\ttrain-mlogloss:0.26814\ttest-mlogloss:0.27062\n",
      "[38]\ttrain-mlogloss:0.26775\ttest-mlogloss:0.27030\n",
      "[39]\ttrain-mlogloss:0.26744\ttest-mlogloss:0.27001\n",
      "[40]\ttrain-mlogloss:0.26716\ttest-mlogloss:0.26975\n",
      "[41]\ttrain-mlogloss:0.26679\ttest-mlogloss:0.26954\n",
      "[42]\ttrain-mlogloss:0.26653\ttest-mlogloss:0.26935\n",
      "[43]\ttrain-mlogloss:0.26628\ttest-mlogloss:0.26916\n",
      "[44]\ttrain-mlogloss:0.26608\ttest-mlogloss:0.26902\n",
      "[45]\ttrain-mlogloss:0.26586\ttest-mlogloss:0.26882\n",
      "[46]\ttrain-mlogloss:0.26570\ttest-mlogloss:0.26870\n",
      "[47]\ttrain-mlogloss:0.26552\ttest-mlogloss:0.26860\n",
      "[48]\ttrain-mlogloss:0.26536\ttest-mlogloss:0.26849\n",
      "[49]\ttrain-mlogloss:0.26524\ttest-mlogloss:0.26840\n",
      "[50]\ttrain-mlogloss:0.26509\ttest-mlogloss:0.26832\n",
      "[51]\ttrain-mlogloss:0.26497\ttest-mlogloss:0.26823\n",
      "[52]\ttrain-mlogloss:0.26476\ttest-mlogloss:0.26815\n",
      "[53]\ttrain-mlogloss:0.26467\ttest-mlogloss:0.26808\n",
      "[54]\ttrain-mlogloss:0.26454\ttest-mlogloss:0.26803\n",
      "[55]\ttrain-mlogloss:0.26446\ttest-mlogloss:0.26798\n",
      "[56]\ttrain-mlogloss:0.26429\ttest-mlogloss:0.26793\n",
      "[57]\ttrain-mlogloss:0.26413\ttest-mlogloss:0.26791\n",
      "[58]\ttrain-mlogloss:0.26408\ttest-mlogloss:0.26787\n",
      "[59]\ttrain-mlogloss:0.26396\ttest-mlogloss:0.26784\n",
      "[60]\ttrain-mlogloss:0.26384\ttest-mlogloss:0.26782\n",
      "[61]\ttrain-mlogloss:0.26372\ttest-mlogloss:0.26781\n",
      "[62]\ttrain-mlogloss:0.26362\ttest-mlogloss:0.26780\n",
      "[63]\ttrain-mlogloss:0.26358\ttest-mlogloss:0.26776\n",
      "[64]\ttrain-mlogloss:0.26350\ttest-mlogloss:0.26774\n",
      "[65]\ttrain-mlogloss:0.26347\ttest-mlogloss:0.26773\n",
      "[66]\ttrain-mlogloss:0.26336\ttest-mlogloss:0.26773\n",
      "[67]\ttrain-mlogloss:0.26318\ttest-mlogloss:0.26776\n",
      "[68]\ttrain-mlogloss:0.26311\ttest-mlogloss:0.26775\n",
      "[69]\ttrain-mlogloss:0.26303\ttest-mlogloss:0.26775\n",
      "[70]\ttrain-mlogloss:0.26290\ttest-mlogloss:0.26775\n",
      "[71]\ttrain-mlogloss:0.26288\ttest-mlogloss:0.26775\n",
      "[72]\ttrain-mlogloss:0.26279\ttest-mlogloss:0.26775\n",
      "[73]\ttrain-mlogloss:0.26270\ttest-mlogloss:0.26774\n",
      "[74]\ttrain-mlogloss:0.26261\ttest-mlogloss:0.26774\n",
      "[75]\ttrain-mlogloss:0.26249\ttest-mlogloss:0.26776\n",
      "[76]\ttrain-mlogloss:0.26240\ttest-mlogloss:0.26777\n",
      "[77]\ttrain-mlogloss:0.26233\ttest-mlogloss:0.26777\n",
      "[78]\ttrain-mlogloss:0.26227\ttest-mlogloss:0.26778\n",
      "[79]\ttrain-mlogloss:0.26221\ttest-mlogloss:0.26778\n",
      "[80]\ttrain-mlogloss:0.26216\ttest-mlogloss:0.26780\n",
      "[81]\ttrain-mlogloss:0.26213\ttest-mlogloss:0.26779\n",
      "[82]\ttrain-mlogloss:0.26211\ttest-mlogloss:0.26779\n",
      "[83]\ttrain-mlogloss:0.26206\ttest-mlogloss:0.26780\n",
      "[84]\ttrain-mlogloss:0.26203\ttest-mlogloss:0.26781\n",
      "[85]\ttrain-mlogloss:0.26194\ttest-mlogloss:0.26782\n",
      "[86]\ttrain-mlogloss:0.26189\ttest-mlogloss:0.26783\n",
      "[87]\ttrain-mlogloss:0.26176\ttest-mlogloss:0.26786\n",
      "[88]\ttrain-mlogloss:0.26167\ttest-mlogloss:0.26790\n",
      "[89]\ttrain-mlogloss:0.26164\ttest-mlogloss:0.26791\n",
      "[90]\ttrain-mlogloss:0.26154\ttest-mlogloss:0.26793\n",
      "[91]\ttrain-mlogloss:0.26151\ttest-mlogloss:0.26793\n",
      "[92]\ttrain-mlogloss:0.26149\ttest-mlogloss:0.26793\n",
      "[93]\ttrain-mlogloss:0.26141\ttest-mlogloss:0.26793\n",
      "[94]\ttrain-mlogloss:0.26138\ttest-mlogloss:0.26794\n",
      "[95]\ttrain-mlogloss:0.26138\ttest-mlogloss:0.26794\n",
      "[96]\ttrain-mlogloss:0.26128\ttest-mlogloss:0.26794\n",
      "[97]\ttrain-mlogloss:0.26120\ttest-mlogloss:0.26797\n",
      "[98]\ttrain-mlogloss:0.26110\ttest-mlogloss:0.26798\n",
      "[99]\ttrain-mlogloss:0.26104\ttest-mlogloss:0.26798\n",
      "[100]\ttrain-mlogloss:0.26096\ttest-mlogloss:0.26798\n",
      "[101]\ttrain-mlogloss:0.26091\ttest-mlogloss:0.26799\n",
      "[102]\ttrain-mlogloss:0.26084\ttest-mlogloss:0.26798\n",
      "[103]\ttrain-mlogloss:0.26079\ttest-mlogloss:0.26800\n",
      "[104]\ttrain-mlogloss:0.26073\ttest-mlogloss:0.26801\n",
      "[105]\ttrain-mlogloss:0.26069\ttest-mlogloss:0.26800\n",
      "[106]\ttrain-mlogloss:0.26063\ttest-mlogloss:0.26800\n",
      "[107]\ttrain-mlogloss:0.26059\ttest-mlogloss:0.26800\n",
      "[108]\ttrain-mlogloss:0.26059\ttest-mlogloss:0.26800\n",
      "[109]\ttrain-mlogloss:0.26057\ttest-mlogloss:0.26800\n",
      "[110]\ttrain-mlogloss:0.26050\ttest-mlogloss:0.26803\n",
      "[111]\ttrain-mlogloss:0.26046\ttest-mlogloss:0.26805\n",
      "[112]\ttrain-mlogloss:0.26043\ttest-mlogloss:0.26805\n",
      "[113]\ttrain-mlogloss:0.26038\ttest-mlogloss:0.26805\n",
      "[114]\ttrain-mlogloss:0.26038\ttest-mlogloss:0.26805\n",
      "[115]\ttrain-mlogloss:0.26030\ttest-mlogloss:0.26807\n",
      "[116]\ttrain-mlogloss:0.26029\ttest-mlogloss:0.26807\n",
      "[117]\ttrain-mlogloss:0.26026\ttest-mlogloss:0.26807\n",
      "[118]\ttrain-mlogloss:0.26020\ttest-mlogloss:0.26806\n",
      "[119]\ttrain-mlogloss:0.26017\ttest-mlogloss:0.26808\n",
      "[120]\ttrain-mlogloss:0.26011\ttest-mlogloss:0.26810\n",
      "[121]\ttrain-mlogloss:0.26004\ttest-mlogloss:0.26811\n",
      "[122]\ttrain-mlogloss:0.25999\ttest-mlogloss:0.26810\n",
      "[123]\ttrain-mlogloss:0.25997\ttest-mlogloss:0.26810\n",
      "[124]\ttrain-mlogloss:0.25993\ttest-mlogloss:0.26810\n",
      "[125]\ttrain-mlogloss:0.25985\ttest-mlogloss:0.26813\n",
      "[126]\ttrain-mlogloss:0.25978\ttest-mlogloss:0.26815\n",
      "[127]\ttrain-mlogloss:0.25973\ttest-mlogloss:0.26817\n",
      "[128]\ttrain-mlogloss:0.25969\ttest-mlogloss:0.26816\n",
      "[129]\ttrain-mlogloss:0.25959\ttest-mlogloss:0.26819\n",
      "[130]\ttrain-mlogloss:0.25945\ttest-mlogloss:0.26821\n",
      "[131]\ttrain-mlogloss:0.25937\ttest-mlogloss:0.26821\n",
      "[132]\ttrain-mlogloss:0.25936\ttest-mlogloss:0.26822\n",
      "[133]\ttrain-mlogloss:0.25930\ttest-mlogloss:0.26821\n",
      "[134]\ttrain-mlogloss:0.25923\ttest-mlogloss:0.26823\n",
      "[135]\ttrain-mlogloss:0.25919\ttest-mlogloss:0.26823\n",
      "[136]\ttrain-mlogloss:0.25911\ttest-mlogloss:0.26826\n",
      "[137]\ttrain-mlogloss:0.25900\ttest-mlogloss:0.26827\n",
      "[138]\ttrain-mlogloss:0.25894\ttest-mlogloss:0.26828\n",
      "[139]\ttrain-mlogloss:0.25890\ttest-mlogloss:0.26829\n",
      "[140]\ttrain-mlogloss:0.25889\ttest-mlogloss:0.26829\n",
      "[141]\ttrain-mlogloss:0.25889\ttest-mlogloss:0.26829\n",
      "[142]\ttrain-mlogloss:0.25888\ttest-mlogloss:0.26830\n",
      "[143]\ttrain-mlogloss:0.25881\ttest-mlogloss:0.26833\n",
      "[144]\ttrain-mlogloss:0.25881\ttest-mlogloss:0.26833\n",
      "[145]\ttrain-mlogloss:0.25881\ttest-mlogloss:0.26833\n",
      "[146]\ttrain-mlogloss:0.25876\ttest-mlogloss:0.26833\n",
      "[147]\ttrain-mlogloss:0.25874\ttest-mlogloss:0.26834\n",
      "[148]\ttrain-mlogloss:0.25870\ttest-mlogloss:0.26834\n",
      "[149]\ttrain-mlogloss:0.25867\ttest-mlogloss:0.26834\n",
      "[150]\ttrain-mlogloss:0.25863\ttest-mlogloss:0.26836\n",
      "[151]\ttrain-mlogloss:0.25861\ttest-mlogloss:0.26836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152]\ttrain-mlogloss:0.25857\ttest-mlogloss:0.26837\n",
      "[153]\ttrain-mlogloss:0.25851\ttest-mlogloss:0.26837\n",
      "[154]\ttrain-mlogloss:0.25840\ttest-mlogloss:0.26839\n",
      "[155]\ttrain-mlogloss:0.25833\ttest-mlogloss:0.26839\n",
      "[156]\ttrain-mlogloss:0.25825\ttest-mlogloss:0.26837\n",
      "[157]\ttrain-mlogloss:0.25818\ttest-mlogloss:0.26840\n",
      "[158]\ttrain-mlogloss:0.25811\ttest-mlogloss:0.26842\n",
      "[159]\ttrain-mlogloss:0.25810\ttest-mlogloss:0.26841\n",
      "[160]\ttrain-mlogloss:0.25807\ttest-mlogloss:0.26842\n",
      "[161]\ttrain-mlogloss:0.25804\ttest-mlogloss:0.26842\n",
      "[162]\ttrain-mlogloss:0.25800\ttest-mlogloss:0.26843\n",
      "[163]\ttrain-mlogloss:0.25796\ttest-mlogloss:0.26844\n",
      "[164]\ttrain-mlogloss:0.25792\ttest-mlogloss:0.26845\n",
      "[165]\ttrain-mlogloss:0.25788\ttest-mlogloss:0.26845\n",
      "[166]\ttrain-mlogloss:0.25783\ttest-mlogloss:0.26846\n",
      "[167]\ttrain-mlogloss:0.25783\ttest-mlogloss:0.26846\n",
      "[168]\ttrain-mlogloss:0.25782\ttest-mlogloss:0.26846\n",
      "[169]\ttrain-mlogloss:0.25782\ttest-mlogloss:0.26846\n",
      "[170]\ttrain-mlogloss:0.25782\ttest-mlogloss:0.26846\n",
      "[171]\ttrain-mlogloss:0.25782\ttest-mlogloss:0.26846\n",
      "[172]\ttrain-mlogloss:0.25778\ttest-mlogloss:0.26845\n",
      "[173]\ttrain-mlogloss:0.25777\ttest-mlogloss:0.26846\n",
      "[174]\ttrain-mlogloss:0.25774\ttest-mlogloss:0.26846\n",
      "[175]\ttrain-mlogloss:0.25773\ttest-mlogloss:0.26846\n",
      "[176]\ttrain-mlogloss:0.25771\ttest-mlogloss:0.26847\n",
      "[177]\ttrain-mlogloss:0.25771\ttest-mlogloss:0.26846\n",
      "[178]\ttrain-mlogloss:0.25768\ttest-mlogloss:0.26847\n",
      "[179]\ttrain-mlogloss:0.25764\ttest-mlogloss:0.26849\n",
      "[180]\ttrain-mlogloss:0.25758\ttest-mlogloss:0.26852\n",
      "[181]\ttrain-mlogloss:0.25750\ttest-mlogloss:0.26853\n",
      "[182]\ttrain-mlogloss:0.25748\ttest-mlogloss:0.26855\n",
      "[183]\ttrain-mlogloss:0.25746\ttest-mlogloss:0.26856\n",
      "[184]\ttrain-mlogloss:0.25743\ttest-mlogloss:0.26856\n",
      "[185]\ttrain-mlogloss:0.25738\ttest-mlogloss:0.26856\n",
      "[186]\ttrain-mlogloss:0.25731\ttest-mlogloss:0.26859\n",
      "[187]\ttrain-mlogloss:0.25723\ttest-mlogloss:0.26860\n",
      "[188]\ttrain-mlogloss:0.25713\ttest-mlogloss:0.26861\n",
      "[189]\ttrain-mlogloss:0.25710\ttest-mlogloss:0.26861\n",
      "[190]\ttrain-mlogloss:0.25708\ttest-mlogloss:0.26863\n",
      "[191]\ttrain-mlogloss:0.25708\ttest-mlogloss:0.26863\n",
      "[192]\ttrain-mlogloss:0.25703\ttest-mlogloss:0.26863\n",
      "[193]\ttrain-mlogloss:0.25700\ttest-mlogloss:0.26863\n",
      "[194]\ttrain-mlogloss:0.25696\ttest-mlogloss:0.26863\n",
      "[195]\ttrain-mlogloss:0.25694\ttest-mlogloss:0.26862\n",
      "[196]\ttrain-mlogloss:0.25691\ttest-mlogloss:0.26864\n",
      "[197]\ttrain-mlogloss:0.25688\ttest-mlogloss:0.26863\n",
      "[198]\ttrain-mlogloss:0.25683\ttest-mlogloss:0.26862\n",
      "[199]\ttrain-mlogloss:0.25679\ttest-mlogloss:0.26865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93     44198\n",
      "         1.0       0.98      0.29      0.44      8882\n",
      "         2.0       1.00      1.00      1.00        15\n",
      "         3.0       1.00      1.00      1.00       480\n",
      "\n",
      "    accuracy                           0.88     53575\n",
      "   macro avg       0.96      0.82      0.84     53575\n",
      "weighted avg       0.89      0.88      0.85     53575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix( X_test, label=y_test)\n",
    "#1.训练模型\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.2\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 4\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 150\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "\n",
    "pred = bst.predict( xg_test );\n",
    "\n",
    "print(classification_report(y_test, pred)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8a767fc116d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"\"\"\n\u001b[1;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 995\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 375\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    467\u001b[0m                     \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 },\n\u001b[0;32m--> 469\u001b[0;31m                 args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_optimize_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0;32m--> 177\u001b[0;31m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# Forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_lyh/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(50,50), max_iter=200, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)  \n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
